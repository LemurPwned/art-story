{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 162,
   "source": [
    "import os\n",
    "import glob\n",
    "import pickle\n",
    "import numpy as np\n",
    "import ujson as json\n",
    "from tqdm.notebook import tqdm\n",
    "from collections import defaultdict, Counter\n",
    "from typing import Iterable, List\n",
    "from gensim.test.utils import simple_preprocess\n",
    "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
    "\n",
    "\n",
    "def process_corpus(author_fn, tokens_only=False) -> Iterable[List[str]]:\n",
    "    with open(author_fn, 'r') as f:\n",
    "        data = json.load(f)\n",
    "        for author, author_data in data.items():\n",
    "            wiki_note = author_data['note']\n",
    "            for i, line in enumerate(wiki_note.split(\"\\n\")):\n",
    "                tokens = simple_preprocess(line)\n",
    "                if tokens_only:\n",
    "                    yield tokens\n",
    "                else:\n",
    "                    # For training data, add tags\n",
    "                    yield TaggedDocument(tokens, [i])\n",
    "\n",
    "\n",
    "def iterable_corpus(train_docs: List[str], tags: List[str] = None, text_mode=True):\n",
    "    for i, doc in enumerate(train_docs):\n",
    "        tokens = simple_preprocess(doc)\n",
    "        if text_mode:\n",
    "            # use the text similarity\n",
    "            yield TaggedDocument(tokens, [i])\n",
    "        elif tags is not None:\n",
    "            # use the tag similarity\n",
    "            yield TaggedDocument(tokens, tags[i])\n",
    "        else:\n",
    "            yield tokens\n",
    "\n",
    "\n",
    "CODED_TAGS = ['genre', 'style', 'material']\n",
    "\n",
    "\n",
    "def read_artwork_desc(src_folder: os.PathLike):\n",
    "    \"\"\"\n",
    "    Read the available descriptions\n",
    "    \"\"\"\n",
    "    description_corpus = defaultdict(list)\n",
    "    for author in tqdm(glob.glob(src_folder)):\n",
    "        author_json = json.load(open(author, 'r'))\n",
    "        for work in author_json:\n",
    "            desc = work.get(\"description\", None)\n",
    "            if desc:\n",
    "\n",
    "                tags = work.get(\"tags\", None)\n",
    "                ensemble_tags = []\n",
    "                if tags:\n",
    "                    tags = tags.lower().split(', ')\n",
    "                    ensemble_tags.extend(tags)\n",
    "                for subtag in CODED_TAGS:\n",
    "                    st = work.get(subtag, None)\n",
    "                    if st:\n",
    "                        st = st.lower().strip()\n",
    "                        if ',' in st:\n",
    "                            st = st.split(', ')\n",
    "                            ensemble_tags.extend(st)\n",
    "                        else:\n",
    "                            ensemble_tags.append(st)\n",
    "                if not ensemble_tags:\n",
    "                    continue\n",
    "                description_corpus['tags'].append(ensemble_tags)\n",
    "                description_corpus['author'].append(\n",
    "                    work.get(\"artistName\", \"Unknown\"))\n",
    "                description_corpus['description'].append(\n",
    "                    desc.replace(\"[/i]\", \"\").replace(\"[i]\", \"\"))\n",
    "                description_corpus['title'].append(\n",
    "                    work.get(\"title\", \"Untitles\"))\n",
    "    print(\"Gathered\", len(description_corpus['tags']))\n",
    "    pickle.dump(description_corpus, open('description.pkl', 'wb'))\n",
    "    return description_corpus\n",
    "\n",
    "\n",
    "d = read_artwork_desc(src_folder='/Users/jm/data/wikiart/meta/*.json')\n"
   ],
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  0%|          | 0/2042 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "92fc9d8931644d97899d99cc62b5b746"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Gathered 2649\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "TEXT_MODE = False\n",
    "\n",
    "rng = np.random.default_rng(seed=42)\n",
    "artwork_descriptions = pickle.load(open('description.pkl', 'rb'))\n",
    "indices = np.arange(0, len(artwork_descriptions['description']), 1)\n",
    "ratio = 0.8\n",
    "train_indices = rng.choice(indices, size=int(\n",
    "    ratio*len(indices)), replace=False)\n",
    "test_indices = indices[~np.isin(indices, train_indices)]\n",
    "all_docs = np.asarray(artwork_descriptions['description'])\n",
    "all_tags = np.asarray(artwork_descriptions['tags'], dtype=object)\n",
    "print(f\"All docs: {all_docs.shape}\")\n",
    "train_docs = list(iterable_corpus(\n",
    "    all_docs[train_indices], tags=all_tags[train_indices], text_mode=TEXT_MODE))\n",
    "test_docs = list(iterable_corpus(all_docs[test_indices], text_mode=False))\n",
    "model = Doc2Vec(vector_size=100, min_count=1, epochs=50)\n",
    "model.build_vocab(train_docs)\n",
    "model.train(train_docs, total_examples=model.corpus_count, epochs=model.epochs)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "source": [
    "ranks = []\n",
    "# some ranks are a miss, but there are plenty of the that did not hit\n",
    "for doc_id in range(len(train_docs)):\n",
    "    tags = train_docs[doc_id].tags\n",
    "    inferred_vector = model.infer_vector(train_docs[doc_id].words)\n",
    "    sims = model.dv.most_similar([inferred_vector], topn=len(model.dv))\n",
    "    ranking = [docid for docid, _ in sims]\n",
    "    best_rank = min([len(ranking)] + [ranking.index(tag) +\n",
    "                    1 for tag in tags if tag in ranking])\n",
    "    ranks.append(best_rank)\n",
    "ranker = Counter(ranks)\n",
    "print(\"Top ranks\", ranker.most_common(10))\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Top ranks [(1, 768), (2, 53), (3, 41), (4, 24), (7, 24), (5, 24), (23, 22), (8, 21), (24, 20), (17, 19)]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "source": [
    "doc_id = rng.choice(range(len(test_docs)))\n",
    "if TEXT_MODE:\n",
    "    inferred_vector = model.infer_vector(test_docs[doc_id].words)\n",
    "    sims = model.dv.most_similar([inferred_vector], topn=len(model.dv))\n",
    "    print('Test Document ({}): «{}»\\n'.format(\n",
    "        doc_id, ' '.join(test_docs[doc_id].words)))\n",
    "    print(u'SIMILAR/DISSIMILAR DOCS PER MODEL %s:\\n' % model)\n",
    "    for label, index in [('MOST', 0), ('MEDIAN', len(sims)//2), ('LEAST', len(sims) - 1)]:\n",
    "        text = train_docs[sims[index][0]].words\n",
    "        print(u'%s %s: «%s»\\n' % (label, sims[index], ' '.join(text)))\n",
    "else:\n",
    "    inferred_vector = model.infer_vector(test_docs[doc_id])\n",
    "    sims = model.dv.most_similar([inferred_vector], topn=len(model.dv))\n",
    "    # Compare and print the most/median/least similar documents from the train corpus\n",
    "    print('Test Document ({}): «{}»\\n'.format(\n",
    "        doc_id, ' '.join(test_docs[doc_id])))\n",
    "    print(u'SIMILAR/DISSIMILAR DOCS PER MODEL %s:\\n' % model)\n",
    "    for label, index in [('MOST', 0), ('MEDIAN', len(sims)//2), ('LEAST', len(sims) - 1)]:\n",
    "        print(u'%s %s: «%s»\\n' %\n",
    "              (label, sims[index], ' '.join(sims[index][0])))\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Test Document (10): «this amphora is decorated on both sides but in different painting techniques one side has scene depicted in the red figure style and the other side shows the same scene in the black figure style this type of decoration puts the vase into the so called bilingual group the traditional attributions for the painter is the red figure side is by the andokides painter and the black figure side is by the lysippides painter this scene known from other representations in greek art depicts the heroes achilles and ajax playing board game the warriors wear their helmets and hold two spears each ajax has his right hand near the board ready to play when his turn comes both heroes wear short tunics chitoniskoi and are armed with corslet cushes greaves they wear short cloaks over their armour behind them their shields lean against something with their helmets perched on top behind them or beside them at arm reach both sit with the hither leg drawn back ajax is farther from the table than achilles although he sits farther forward on his block thakos condition large pieces have been restored on side heads are restored url href https www mfa org collections object two handled jar amphora with achilles and ajax mfa url»\n",
      "\n",
      "SIMILAR/DISSIMILAR DOCS PER MODEL Doc2Vec(dm/m,d100,n5,w5,s0.001,t3):\n",
      "\n",
      "MOST ('archaic', 0.5540852546691895): «a r c h a i c»\n",
      "\n",
      "MEDIAN ('escarpment', 0.14637646079063416): «e s c a r p m e n t»\n",
      "\n",
      "LEAST ('rose', -0.35279279947280884): «r o s e»\n",
      "\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Elasticsearch index"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "from elasticsearch.helpers import streaming_bulk\n",
    "from typing import Dict, Any\n",
    "\n",
    "\n",
    "def create_painting_index(indx: str, es: Elasticsearch, feature_dims: int = 2048,\n",
    "                          text_dims: int = 50):\n",
    "    dense_paintings = {\n",
    "        \"mappings\": {\n",
    "            \"properties\": {\n",
    "                # \"img_vector\": {\n",
    "                #     \"type\": \"dense_vector\",\n",
    "                #     \"dims\": feature_dims\n",
    "                # },\n",
    "                # \"text_vector\": {\n",
    "                #     \"type\": \"dense_vector\",\n",
    "                #     \"dims\": text_dims\n",
    "                # },\n",
    "                \"description\": {\n",
    "                    \"type\": \"text\"\n",
    "                },\n",
    "                \"style\": {\n",
    "                    \"type\": \"keyword\"\n",
    "                },\n",
    "                \"genre\": {\n",
    "                    \"type\": \"keyword\"\n",
    "                },\n",
    "                \"material\": {\n",
    "                    \"type\": \"keyword\"\n",
    "                },\n",
    "                \"title\": {\n",
    "                    \"type\": \"text\"\n",
    "                },\n",
    "                \"author\": {\n",
    "                    \"type\": \"keyword\"\n",
    "                },\n",
    "                \"url\": {\n",
    "                    \"type\": \"text\"\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    es.indices.delete(indx, ignore=[400, 404])\n",
    "    es.indices.create(index=indx, body=dense_paintings)\n",
    "\n",
    "\n",
    "def stream_painting_docs(index: str, src_folder: os.PathLike) -> Iterable[Dict[str, Any]]:\n",
    "    for author in tqdm(glob.glob(src_folder)):\n",
    "        author_json = json.load(open(author, 'r'))\n",
    "        for work in author_json:\n",
    "            desc = work.get(\"description\", None)\n",
    "            if desc:\n",
    "                tags = work.get(\"tags\", None)\n",
    "                extra_tags = {tag: work.get(tag, None) for tag in CODED_TAGS}\n",
    "                yield {\n",
    "                    \"_index\": index,\n",
    "                    \"_source\": {\n",
    "                        \"url\": work.get(\"image\", None),\n",
    "                        **extra_tags,\n",
    "                        \"tags\": tags.split(\",\"),\n",
    "                        \"description\": work.get(\"description\", None),\n",
    "                        \"author\": work.get(\"artistName\", \"Unknown\"),\n",
    "                        \"title\": work.get(\"title\", \"Untitled\")\n",
    "                    }\n",
    "                }\n",
    "\n",
    "\n",
    "def create_author_index(indx: str, es: Elasticsearch, text_dims: int = 50):\n",
    "    dense_paintings = {\n",
    "        \"mappings\": {\n",
    "            \"properties\": {\n",
    "                \"text_vector\": {\n",
    "                    \"type\": \"dense_vector\",\n",
    "                    \"dims\": text_dims\n",
    "                },\n",
    "                \"author\": {\n",
    "                    \"type\": \"keyword\"\n",
    "                },\n",
    "                \"wiki\": {\n",
    "                    \"type\": \"text\"\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    es.indices.delete(indx, ignore=[400, 404])\n",
    "    es.indices.create(index=indx, body=dense_paintings)\n",
    "\n",
    "\n",
    "def search_paintings(es: Elasticsearch, index: str, query: str, query_vector: List[float], ws: int, field_name: str):\n",
    "    query = {\n",
    "        \"query\": {\n",
    "            \"match\": {\n",
    "                \"query\": query\n",
    "            }\n",
    "        },\n",
    "        \"rescore\": [\n",
    "            {\n",
    "                \"window_size\": ws,\n",
    "                \"query\": {\n",
    "                    \"script_score\": {\n",
    "                        \"query\": {\n",
    "                            \"match_all\": {}\n",
    "                        },\n",
    "                        \"script\": {\n",
    "                            \"source\": f\"cosineSimilarity(params.query_vector, '{field_name}') + 1.0\",\n",
    "                            \"params\": {\n",
    "                                \"query_vector\": query_vector\n",
    "\n",
    "                            }\n",
    "                        }\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        ]\n",
    "    }\n",
    "    results = es.search(index=index, body=query)\n",
    "    return results['hits']['hits']\n",
    "\n",
    "\n",
    "es = Elasticsearch()\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "source": [
    "create_painting_index(\"paintings\", es)\n",
    "for ok, response in stream_painting_docs(\n",
    "        index=\"paintings\", src_folder='/Users/jm/data/wikiart/meta/*.json'):\n",
    "    if not ok:\n",
    "        print(response)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/.art/lib/python3.9/site-packages/elasticsearch/connection/base.py:208: ElasticsearchWarning: Elasticsearch built-in security features are not enabled. Without authentication, your cluster could be accessible to anyone. See https://www.elastic.co/guide/en/elasticsearch/reference/7.13/security-minimal-setup.html to enable security.\n",
      "  warnings.warn(message, category=ElasticsearchWarning)\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "  0%|          | 0/2042 [00:00<?, ?it/s]"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "14cc8a6f0c4c466aa4d4b215f833861b"
      }
     },
     "metadata": {}
    },
    {
     "output_type": "error",
     "ename": "TypeError",
     "evalue": "'set' object is not a mapping",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/wq/0q9brtfs5rq65q1t_mtgshb00000gn/T/ipykernel_78579/2627563385.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mcreate_painting_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"paintings\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m for ok, response in stream_painting_docs(\n\u001b[0m\u001b[1;32m      3\u001b[0m         index=\"paintings\", src_folder='/Users/jm/data/wikiart/meta/*.json'):\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mok\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/var/folders/wq/0q9brtfs5rq65q1t_mtgshb00000gn/T/ipykernel_78579/3960365834.py\u001b[0m in \u001b[0;36mstream_painting_docs\u001b[0;34m(index, src_folder)\u001b[0m\n\u001b[1;32m     55\u001b[0m                 yield {\n\u001b[1;32m     56\u001b[0m                     \u001b[0;34m\"_index\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m                     \"_source\": {\n\u001b[0m\u001b[1;32m     58\u001b[0m                         \u001b[0;34m\"url\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mwork\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"image\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m                         \u001b[0;34m**\u001b[0m\u001b[0mextra_tags\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'set' object is not a mapping"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.6",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit ('.art': conda)"
  },
  "interpreter": {
   "hash": "5943960f05fa8d0a4ee77593c6fb6e49e1174e402884489bc47b8b0bccb1272f"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}