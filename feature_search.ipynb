{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np \n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "from tqdm.notebook import tqdm\n",
    "import torchvision.models as models\n",
    "from torchvision import datasets, transforms as T\n",
    "from PIL import Image"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "feature_generator = models.resnext50_32x4d(pretrained=True)\n",
    "normalize = T.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                        std=[0.229, 0.224, 0.225])\n",
    "transform = T.Compose([T.Resize(256),\n",
    "                       T.CenterCrop(224),\n",
    "                       T.ToTensor(),\n",
    "                       normalize])\n",
    "# to generate features disable last layer \n",
    "feature_generator.fc = nn.Sequential()\n",
    "_ = feature_generator.eval()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "import difflib\n",
    "import ujson as json\n",
    "from typing import Iterable, Dict, Any, Tuple, List\n",
    "\n",
    "src = '/Users/jm/data/wikiart/images'\n",
    "meta = '/Users/jm/data/wikiart/meta/'\n",
    "CODED_TAGS = ['style', 'genre', 'material']\n",
    "\n",
    "\n",
    "def locate_painting(meta_folder: str, full_path: str) -> Tuple[List[str], str]:\n",
    "    p = full_path.split(os.sep)\n",
    "    author = p[-2]\n",
    "    name = p[-1].replace(\".jpg\", \"\")\n",
    "    if 'untitled' in name.lower():\n",
    "        return None, None\n",
    "    author = json.load(open(os.path.join(meta_folder, author + \".json\"), 'r'))\n",
    "    titles = [p['title'] for p in author if 'title' in p]\n",
    "    match = difflib.get_close_matches(name, titles, n=1, cutoff=0.7)\n",
    "    if not match:\n",
    "        return None, None\n",
    "    target_painting = author[titles.index(match[0])]\n",
    "    # get tags here\n",
    "    ensemble_tags = []\n",
    "    tags = target_painting.get(\"tags\", None)\n",
    "    if tags:\n",
    "        tags = tags.lower().split(', ')\n",
    "        ensemble_tags.extend(tags)\n",
    "    for subtag in CODED_TAGS:\n",
    "        st = target_painting.get(subtag, None)\n",
    "        if st:\n",
    "            st = st.lower().strip()\n",
    "            if ',' in st:\n",
    "                st = st.split(', ')\n",
    "                ensemble_tags.extend(st)\n",
    "            else:\n",
    "                ensemble_tags.append(st)\n",
    "    return ensemble_tags, target_painting['image']\n",
    "\n",
    "\n",
    "def stream_features(index: str, src_imgs: os.PathLike, src_meta: os.PathLike) -> Iterable[Dict[str, Any]]:\n",
    "    max_count = 5000\n",
    "    for img_fn in tqdm(glob.glob(os.path.join(src_imgs, \"*/*.jpg\")),\n",
    "                       desc='Generating features'):\n",
    "        try:\n",
    "            metadata, img_url = locate_painting(\n",
    "                meta_folder=src_meta, full_path=img_fn)\n",
    "            if not metadata:\n",
    "                continue\n",
    "            feature = generate_feature(img_fn)\n",
    "\n",
    "            yield {\n",
    "                \"_index\": index,\n",
    "                \"_source\": {\n",
    "                    \"img_vector\": feature.tolist()[0],\n",
    "                    \"tags\": metadata,\n",
    "                    \"url\": img_url\n",
    "                }\n",
    "            }\n",
    "            max_count -= 1\n",
    "            if not max_count:\n",
    "                break\n",
    "        except:\n",
    "            print(f\"Failed to process: {os.path.basename(img_fn)}\")\n",
    "\n",
    "\n",
    "def generate_feature(img_path: os.PathLike):\n",
    "    with Image.open(img_path) as img:\n",
    "        img = transform(img)\n",
    "        feature = feature_generator(\n",
    "            img.unsqueeze(0))\n",
    "        # normalize for easier ES search (less compute on script side)\n",
    "        feature = F.normalize(feature).detach().cpu().numpy()\n",
    "        return feature\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "from elasticsearch import Elasticsearch, helpers\n",
    "\n",
    "\n",
    "def create_es_indx(indx: str, es: Elasticsearch, dims: int = 2048):\n",
    "    dense_paintings = {\n",
    "        \"mappings\": {\n",
    "            \"properties\": {\n",
    "                \"img_vector\": {\n",
    "                    \"type\": \"dense_vector\",\n",
    "                    \"dims\": dims\n",
    "                },\n",
    "                \"tags\": {\n",
    "                    \"type\": \"keyword\"\n",
    "                },\n",
    "                \"url\": {\n",
    "                    \"type\": \"text\"\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    es.indices.delete(indx, ignore=[400, 404])\n",
    "    es.indices.create(index=indx, body=dense_paintings)\n",
    "\n",
    "\n",
    "es = Elasticsearch()\n",
    "index_name = \"paintings\"\n",
    "es.info(pretty=True)\n",
    "# create_es_indx(indx=index_name, es=es, dims=2048)\n",
    "# for ok, response in helpers.streaming_bulk(es, stream_features(index_name, src_imgs=src, src_meta=meta)):\n",
    "#     if not ok:\n",
    "#         print(response)\n"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'name': 'd6be162e9295',\n",
       " 'cluster_name': 'docker-cluster',\n",
       " 'cluster_uuid': 'lcLs5bEPSq6zQ6hfAas94A',\n",
       " 'version': {'number': '7.13.4',\n",
       "  'build_flavor': 'default',\n",
       "  'build_type': 'docker',\n",
       "  'build_hash': 'c5f60e894ca0c61cdbae4f5a686d9f08bcefc942',\n",
       "  'build_date': '2021-07-14T18:33:36.673943207Z',\n",
       "  'build_snapshot': False,\n",
       "  'lucene_version': '8.8.2',\n",
       "  'minimum_wire_compatibility_version': '6.8.0',\n",
       "  'minimum_index_compatibility_version': '6.0.0-beta1'},\n",
       " 'tagline': 'You Know, for Search'}"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "source": [
    "import ipywidgets as ipw\n",
    "\n",
    "\n",
    "def vector_query(query_vector, field_name: str = \"img_vector\", n: int = 10):\n",
    "    #  we add +1 since Elasticsearch CANNOT rank negative scores\n",
    "    return {\n",
    "        \"size\": n,\n",
    "        \"query\": {\n",
    "            \"script_score\": {\n",
    "                \"query\": {\n",
    "                    \"match_all\": {}\n",
    "                },\n",
    "                \"script\": {\n",
    "                    \"source\": f\"cosineSimilarity(params.query_vector, '{field_name}') + 1.0\",\n",
    "                    \"params\": {\n",
    "                        \"query_vector\": query_vector\n",
    "\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "\n",
    "\n",
    "def search_elasticsearch(index: str, query: List[float], n: int = 10) -> List[Dict[str, Any]]:\n",
    "    q_format = vector_query(query_vector=query, n=n)\n",
    "    results = es.search(index=index, body=q_format)\n",
    "    hits = results['hits']['hits']\n",
    "    return hits[1:]\n",
    "\n",
    "\n",
    "def display_query_result(query_result: List[Any]):\n",
    "    boxes = []\n",
    "    for res in query_result:\n",
    "        tags = res[\"_source\"][\"tags\"]\n",
    "        url = res[\"_source\"][\"url\"]\n",
    "\n",
    "        img_ = ipw.Image.from_url(url)\n",
    "        img_.height = 320\n",
    "        img_.width = 160\n",
    "        cap = ipw.Label(\", \".join(tags))\n",
    "        boxes.append(ipw.VBox([img_, cap]))\n",
    "\n",
    "    return ipw.VBox(boxes)\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "query_img = glob.glob(os.path.join(src, \"*/*.jpg\"))[-1]\n",
    "feat = generate_feature(query_img).tolist()[0]\n",
    "qr = search_elasticsearch(index=index_name, query=feat)\n",
    "qimg = ipw.Image.from_file(query_img)\n",
    "qimg.height = 320\n",
    "qimg.width = 160\n",
    "vbox = display_query_result(qr)\n",
    "\n",
    "ipw.VBox([qimg, ipw.Label(\"QueryImage^\"), vbox])\n"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/opt/homebrew/Caskroom/miniforge/base/envs/.art/lib/python3.9/site-packages/elasticsearch/connection/base.py:208: ElasticsearchWarning: Elasticsearch built-in security features are not enabled. Without authentication, your cluster could be accessible to anyone. See https://www.elastic.co/guide/en/elasticsearch/reference/7.13/security-minimal-setup.html to enable security.\n",
      "  warnings.warn(message, category=ElasticsearchWarning)\n"
     ]
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": [
       "VBox(children=(Image(value=b'\\xff\\xd8\\xff\\xe0\\x00\\x10JFIF\\x00\\x01\\x01\\x01\\x00`\\x00`\\x00\\x00\\xff\\xdb\\x00C\\x00\\xâ€¦"
      ],
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "84ca9446440a48de9aa6582e097f30fb"
      }
     },
     "metadata": {}
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.9.6",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.9.6 64-bit ('.art': conda)"
  },
  "interpreter": {
   "hash": "5943960f05fa8d0a4ee77593c6fb6e49e1174e402884489bc47b8b0bccb1272f"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}